
# ğŸğŸŒğŸŠ KNN Classifier from Scratch (Using NumPy)

This is a simple Python project where we build a **K-Nearest Neighbors (KNN)** classifier using only **NumPy**. No external machine learning libraries are used.

---

## ğŸ“š What is KNN?

**KNN** is a basic ML algorithm. It works like this:
1. When you give a new point (like a fruit), it looks at the **k nearest points** in the training data.
2. It checks which label (Apple, Banana, Orange) is the most common among those neighbors.
3. It assigns that label to the new point.

---

## ğŸ§¾ Whatâ€™s in the Data?

Each row in the data looks like this:

```python
[weight, size, color_code, label]
```

- Example: `[150, 7.0, 1, 'Apple']`
- We convert labels (`'Apple'`, `'Banana'`, `'Orange'`) into numbers:
  - `'Apple' â†’ 0`
  - `'Banana' â†’ 1`
  - `'Orange' â†’ 2`

---

## ğŸ”§ What the Code Does

### 1. **Prepares the data**
- Encodes labels to numbers
- Separates features (`X`) and labels (`y`)

### 2. **Defines distance functions**
- **Euclidean**: straight-line distance
- **Manhattan**: like grid or city-block distance
- **Minkowski**: general form (we used `p=4`)

### 3. **Builds the KNN classifier**
- Finds the `k` closest neighbors for each test point
- Picks the most common label among those neighbors

### 4. **Predicts test data**
- Predicts labels for some new fruit examples

### 5. **Tests with different k values**
- Tries `k = 1`, `3`, and `5` to see how results change

### 6. **Accuracy function**
- Compares predicted vs actual labels

### 7. **Normalization (Min-Max Scaling)**
- Scales features between 0 and 1 to make things fair

---

## ğŸ§ª Example Predictions

With test data like:

```python
[118, 6.2, 0]  â†’ Banana  
[160, 7.3, 1]  â†’ Apple  
[185, 7.7, 2]  â†’ Orange
```

The model predicts:
```bash
Predictions: [1 0 2]
Converted Predictions: ['Banana', 'Apple', 'Orange']
```

It works great for all tested `k` values!

---

## ğŸ“ˆ Accuracy

We also test how accurate the model is by splitting the data:
- 75% for training
- 25% for testing

Then we calculate how many labels were predicted correctly.

---

## ğŸ›  How to Run

Make sure you have Python and NumPy installed. Then just run:

```bash
python knn_classifier.py
```

---

## âœ… Requirements

Just one library:
```bash
pip install numpy
```

---

## ğŸ“Œ Future Ideas

- Add weighted KNN (closer neighbors get more vote)
- Add support for real-world datasets
- Use k-fold validation

---

## âœŒï¸ Final Note

This project is perfect for beginners who want to **understand how KNN works** from the ground up!
